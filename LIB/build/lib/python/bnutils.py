# Contributors: Siddharth Jain, Aayush Makharia, Vineet Malik, Sourav Suman, Ayush Chauhan, Gaurav Sinha
# Owned by: Adobe Corporation

# Implements utility functions for bayesian networks

import networkx as nx
import pandas as pd
import numpy as np
import itertools
from tqdm import tqdm
from itertools import combinations
from math import pi
from python.simulate import get_random_DAG, random_parameter_generator, assign_node_type, multi_class_softmax_cpd, lin_gaussian_cpd
from category_encoders import OneHotEncoder


def _has_both_edges(graph, x, y):
    """Conditions on the presence of some edges in the graph.
    Args:
        graph: a graph (as a networkx.Graph or networkx.DiGraph)
        x: node in graph
        y: node in graph
    Returns:
        True: if graph has both edges: x-->y and y-->x
        False: otherwise
    """
    return graph.has_edge(x, y) and graph.has_edge(y, x)


def _has_any_edge(graph, x, y):
    """Conditions on the presence of some edges in the graph.
    Args:
        graph: a graph (as a networkx.Graph or networkx.DiGraph)
        x: node in graph
        y: node in graph
    Returns:
        True: if graph has atleast one of the edges: x-->y and y-->x
        False: otherwise
    """
    return graph.has_edge(x, y) or graph.has_edge(y, x)


def _has_only_edge(graph, x, y):
    """Conditions on the presence of some edges in the graph.
    Args:
        graph: a graph (as a networkx.Graph or networkx.DiGraph)
        x: node in graph
        y: node in graph
    Returns:
        True: if graph has edge: x-->y, but doesn't have edge: y-->x
        False: otherwise
    """
    return graph.has_edge(x, y) and (not graph.has_edge(y, x))


def _has_no_edge(graph, x, y):
    """Conditions on the presence of some edges in the graph.
    Args:
        graph: a graph (as a networkx.Graph or networkx.DiGraph)
        x: node in graph
        y: node in graph
    Returns:
        True: if graph doesn't have both the edges: x-->y and y-->x
        False: otherwise
    """
    return not (graph.has_edge(x, y) or graph.has_edge(y, x))


def _has_one_edge(graph, x, y):
    """Conditions on the presence of some edges in the graph.
    Args:
        graph: a graph (as a networkx.Graph or networkx.DiGraph)
        x: node in graph
        y: node in graph
    Returns:
        True: if graph has exactly one of the two edges: x-->y and y-->x
        False: otherwise
    """
    return graph.has_edge(x, y) ^ graph.has_edge(y, x)


def get_CPDAG(graph):
    """Generates Completed Partially DAG from graph.
    Args:
        graph: a graph (as a networkx.Graph or networkx.DiGraph)
    Returns:
        CPDAG, a directed graph (as a networkx.DiGraph)
    """
    nodes = graph.nodes()
    dag = graph.to_undirected().to_directed()

    for (i, j) in combinations(nodes, 2):
        # Checks whether k is an unshielded collider.
        if _has_no_edge(graph, i, j):
            for k in nodes:
                if _has_only_edge(graph, i, k) and _has_only_edge(graph, j, k):
                    if dag.has_edge(k, i):
                        dag.remove_edge(k, i)
                    if dag.has_edge(k, j):
                        dag.remove_edge(k, j)

    old_dag = dag.copy()
    while True:
        for (i, j) in combinations(nodes, 2):
            # Rule 1: Orient i-j into i->j whenever there is an arrow k->i such that k and j are nonadjacent.
            #
            # Check if i-j.
            if _has_both_edges(dag, i, j):
                # Look all the predecessors of i.
                for k in dag.predecessors(i):
                    # Skip if there is an arrow i->k.
                    if dag.has_edge(i, k):
                        continue
                    # Skip if k and j are adjacent.
                    if _has_any_edge(dag, k, j):
                        continue
                    # Make i-j into i->j
                    dag.remove_edge(j, i)
                    break
            # Rule 2: Orient i-j into i->j whenever there is a chain i->k->j.
            #
            # Check if i-j.
            if _has_both_edges(dag, i, j):
                # Find nodes k where k is i->k.
                succs_i = set()
                for k in dag.successors(i):
                    if not dag.has_edge(k, i):
                        succs_i.add(k)
                # Find nodes j where j is k->j.
                preds_j = set()
                for k in dag.predecessors(j):
                    if not dag.has_edge(j, k):
                        preds_j.add(k)
                # Check if there is any node k where i->k->j.
                if len(succs_i & preds_j) > 0:
                    # Make i-j into i->j
                    dag.remove_edge(j, i)
            # Rule 3: Orient i-j into i->j whenever there are two chains i-k->j and i-l->j such that k and l are nonadjacent.
            #
            # Check if i-j.
            if _has_both_edges(dag, i, j):
                # Find nodes k where i-k.
                adj_i = set()
                for k in dag.successors(i):
                    if dag.has_edge(k, i):
                        adj_i.add(k)
                # For all the pairs of nodes in adj_i,
                for (k, l) in combinations(adj_i, 2):
                    # Skip if k and l are adjacent.
                    if _has_any_edge(dag, k, l):
                        continue
                    # Skip if not k->j.
                    if not _has_only_edge(dag, k, j):
                        continue
                    # Skip if not l->j.
                    if not _has_only_edge(dag, l, j):
                        continue
                    # Make i-j into i->j.
                    dag.remove_edge(j, i)
                    break
        if nx.is_isomorphic(dag, old_dag):
            break
        old_dag = dag.copy()

    return dag


def ancestral_sampling(dag, cpd_sampler_functions, num_samples=1):
    """performs ancestral sampling on dag based on CPD
    Args:
        dag: Directed Acyclic Graph for which samples have to be generated
        cpd_sampler_functions: list of functions. A list of cpds where cpd at index i corresponds to cpd for node i.
        num_samples: Number of samples that have to be generated
    Returns:
        Pandas dataframe object containing samples
    """
    if(num_samples <= 0):
        raise ValueError("Not a valid sample size")
    sorted_nodes = list(nx.topological_sort(dag))
    node_ids = list(dag.nodes())
    samples = []
    nodes_idx = {node: idx for idx, node in enumerate(node_ids)}

    for sam_num in tqdm(range(num_samples)):
        # Sampling for each node in topological sorted manner
        cur_sample = [None] * len(node_ids)
        for target_node in sorted_nodes:
            cur_sample[nodes_idx[target_node]] = cpd_sampler_functions[nodes_idx[target_node]](dag, target_node, cur_sample)
        samples.append(cur_sample)

    return pd.DataFrame(samples, columns=node_ids)


def one_hot_encoder(x):
    """Encode categorical variables as one-hot encoding
    Args:
        x: categorical variable x
    Returns:
        one hot encoding of x
    """
    enc = OneHotEncoder(cols=[0], handle_unknown='indicator').fit(x)
    x = enc.transform(x).to_numpy()
    return x


def conditional_gaussian_likelihood(df, node, z_disc, z_cont, levels, nodes):
    """Calculates likelihood and degree of freedom for the variable 'node' conditioned on set Z
    Args:
        df: Pandas dataframe object for the sampled data
        node: target node of the graph
        z_disc, z_cont: set of discrete and continuous variables in Z respectively
        levels: list of number of categories of the discrete variables in Z
        nodes: dictionary of nodes and its attributes in graph

    Returns:
        likelihood, degree of freedom
    """

    def discrete_parent(node_list, levels):
        """used to generate all possible combinations of discrete parents"""
        categories_arr = []
        # gets a list of categories list for each discrete parent
        for k in node_list:
            categories_arr.append(list(range(levels[node_list.index(k)])))
        # return the cross_product of all lists present in categories_arr
        return list(itertools.product(*categories_arr))

    def get_likelihood_and_dof(disc_list, cont_list, levels):
        """used to calculate likelihood and degree of freedom given the list of discrete and continuous variables"""
        ll, dof = 0, 0
        par_val = discrete_parent(disc_list, levels)
        for i in par_val:
            Df_req = df
            for itr in zip(disc_list, i):
                Df_req = Df_req.loc[Df_req[itr[0]] == itr[1]]
            Df_req = Df_req[cont_list].to_numpy()
            d = Df_req.shape[1]
            Np = Df_req.shape[0]
            if Np == 0:
                continue
            mu = np.mean(Df_req, axis=0)
            Df_req = Df_req - mu
#             covariance = np.zeros((Df_req.shape[1], Df_req.shape[1]))
#             for row in Df_req:
#                 covariance += np.multiply.outer(row, row)
            covariance = np.dot(np.transpose(Df_req), Df_req)
            covariance = covariance/Df_req.shape[0]
            det = np.linalg.det(covariance)
            if det != 0:
                ll += -(Np / 2) * (np.log(abs(det)) + d * np.log(2 * pi) + d) + Np * np.log(Np / df.shape[0])
                dof += (d * (d + 1) / 2) + 1
            else:
                ll += Np * np.log(Np / df.shape[0])
                dof += (d * (d + 1) / 2) + 1
        dof -= 1
        return ll, dof
    ll0, dof0 = get_likelihood_and_dof(z_disc, z_cont, levels)
    z_disc_with_node = z_disc.copy()
    z_cont_with_node = z_cont.copy()
    levels_with_node = levels.copy()
    z_disc_with_node.append(node) if nodes[node]['type'] == 'disc' else z_cont_with_node.append(node)
    if(nodes[node]['type'] == 'disc'):
        levels_with_node.append(nodes[node]['num_categories'])
    ll1, dof1 = get_likelihood_and_dof(z_disc_with_node, z_cont_with_node, levels_with_node)
    return ll1 - ll0, dof1 - dof0


def data_generator(nodes, graph_density, node_type_ratio, sample_size):
    """
    Generates a random DAG and samples data from it

    Args:
        nodes: number of nodes required in the random DAG
        graph_density: required graph density of the random DAG to be generated
        node_type_ratio: ratio of continuous type nodes to total nodes in graph where value 1 means all continuous nodes
        sample_size: required size of data sampled from the DAG
    Returns:
        dag: netwrokx object of random DAG
        df: pandas dataframe object of sampled data from the DAG
    """
    dag = get_random_DAG(nodes, graph_density = graph_density)
    assign_node_type(dag, node_type_ratio, 3, 5)
    random_parameter_generator(dag)
    func_list = []
    for node in dag.nodes():
        func_list.append(multi_class_softmax_cpd) if(dag.nodes[node]['type'] == 'disc') else func_list.append(lin_gaussian_cpd)
    df = ancestral_sampling(dag, func_list, sample_size)
    return dag, df


def column_mapping(data):
    """
    Maps column names from 0 to total column count

    Args:
        data: pandas dataframe object with string type names
    Returns:
        forward_col_mapping: dictionary with mapping from original column names to dummy names
        backward_col_mapping: dictionary with mapping from dummy names to original column names
    """
    forward_col_mapping = {}
    backward_col_mapping = {}
    for (i, col) in enumerate(data.columns):
        forward_col_mapping[col] = i
        backward_col_mapping[i] = col
    return (forward_col_mapping, backward_col_mapping)


def pre_processing(data, custom=False, cont_columns=[], max_categories=20):
    """
    Preprocesses the names and data_types of columns to make it runnable on algorithms
    
    Args:
        data: pandas dataframe object with string type names
        custom: True if user has prior knowledge about which columns are continuous
        cont_columns: If custom is true, then user can specify the names of continuous columns as list
        max_categories: If custom is false, then user can specify the maximum number of categories of categorical variables in the dataset
    Returns:
        data: pandas dataframe after processing
        args: networkx object containing the data type and number of categories of different variables
        mappers: tuple containing (forward mapping, backward mapping) for data columns
        cat_mappers: dict containing mapping of categorical values
    """
    nodes = []
    args = nx.DiGraph()
    cat_mappers = dict()
    mappers = column_mapping(data)
    data.rename(columns = mappers[0],inplace=True)
    args.add_nodes_from(list(data.columns))
    if not custom:
        for col in data.columns:
            categories = len(pd.Series.unique(data[col]))
            if(categories > max_categories):
                args.nodes[col]['type'] = 'cont'
                args.nodes[col]['num_categories'] = 'NA'
            else:
                args.nodes[col]['type'] = 'disc'
                args.nodes[col]['num_categories'] = categories
                cat_mappers[col] = (pd.unique(data[col]), list(range(pd.unique(data[col]).shape[0])))
                data = data.replace({col: cat_mappers[col][0]}, {col: cat_mappers[col][1]})        
    else:
        for col in data.columns:
            categories = len(pd.Series.unique(data[col]))
            if mappers[1][col] in cont_columns:
                args.nodes[col]['type'] = 'cont'
                args.nodes[col]['num_categories'] = 'NA'
            else:
                args.nodes[col]['type'] = 'disc'
                args.nodes[col]['num_categories'] = categories
                cat_mappers[col] = (pd.unique(data[col]), list(range(pd.unique(data[col]).shape[0])))
                data = data.replace({col: cat_mappers[col][0]}, {col: cat_mappers[col][1]})
    
    return (data, args, mappers, cat_mappers)
